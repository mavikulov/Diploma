{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPe8CZorhEBVIS791h/6kWn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavikulov/Diploma/blob/main/ConvNext2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lmHRF-MwISa",
        "outputId": "b9f10133-0d3f-4a6a-ef76-76eface42b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-14 13:48:23--  https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 813 [text/plain]\n",
            "Saving to: ‘tiny_img.py’\n",
            "\n",
            "\rtiny_img.py           0%[                    ]       0  --.-KB/s               \rtiny_img.py         100%[===================>]     813  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-14 13:48:23 (67.8 MB/s) - ‘tiny_img.py’ saved [813/813]\n",
            "\n",
            "--2025-01-14 13:48:23--  https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img_dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1555 (1.5K) [text/plain]\n",
            "Saving to: ‘tiny_img_dataset.py’\n",
            "\n",
            "tiny_img_dataset.py 100%[===================>]   1.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-14 13:48:23 (28.6 MB/s) - ‘tiny_img_dataset.py’ saved [1555/1555]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget --no-check-certificate 'https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img.py' -O tiny_img.py\n",
        "! wget --no-check-certificate 'https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img_dataset.py' -O tiny_img_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PkLeqUZJHE_f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tiny_img import download_tinyImg200\n",
        "data_path = '.'\n",
        "download_tinyImg200(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F07XIJEDwMqh",
        "outputId": "4cc30af0-ed86-49ed-9fc8-82651d9085db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset was downloaded to './tiny-imagenet-200.zip'\n",
            "Extract downloaded dataset to '.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "\n",
        "def get_computing_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device\n",
        "\n",
        "device = get_computing_device()\n",
        "print(f\"Our main computing device is '{device}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFOBcqFdwtJR",
        "outputId": "b02c14e1-17f3-47a5-9223-45ad7439c911"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our main computing device is 'cuda:0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.RandomRotation(5),\n",
        "     transforms.ColorJitter(brightness=0.9, contrast=0.7, saturation=0.8, hue=0.2)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "qk9VwucFw9rg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiny_img_dataset\n",
        "# you may use torchvision.datasets.ImageFolder() with the same parameters for loading train dataset\n",
        "train_dataset = tiny_img_dataset.TinyImagenetRAM('tiny-imagenet-200/train', transform=train_transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVJMtkFM3wkV",
        "outputId": "e5079487-ac97-41ee-b3ff-3eb383232be4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tiny-imagenet-200/train: 100%|██████████| 200/200 [01:42<00:00,  1.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class TinyImagenetValDataset(Dataset):\n",
        "  def __init__(self, root, transform=transforms.ToTensor):\n",
        "      super().__init__()\n",
        "\n",
        "      self.root = root\n",
        "      with open(os.path.join(root, 'val_annotations.txt')) as f:\n",
        "        annotations = []\n",
        "        for line in f:\n",
        "          img_name, class_label = line.split('\\t')[:2]\n",
        "          annotations.append((img_name, class_label))\n",
        "\n",
        "      # 1. define self.classes - list of sorted class labels from annotations\n",
        "      # it should look like self.classes from \"TinyImagenetRAM\"\n",
        "      # YOUR CODE\n",
        "      self.classes = sorted(set(i[1] for i in annotations))\n",
        "\n",
        "      assert len(self.classes) == 200, len(self.classes)\n",
        "      assert all(self.classes[i] < self.classes[i+1] for i in range(len(self.classes)-1)), 'classes should be ordered'\n",
        "      assert all(isinstance(elem, type(annotations[0][1])) for elem in self.classes), 'your just need to reuse class_labels'\n",
        "\n",
        "      # 2. self.class_to_idx - dict from class label to class index\n",
        "      self.class_to_idx = {item: index for index, item in enumerate(self.classes)}\n",
        "\n",
        "      self.transform = transform\n",
        "\n",
        "      self.images, self.targets = [], []\n",
        "      for img_name, class_name in tqdm.tqdm(annotations, desc=root):\n",
        "        img_name = os.path.join(root, 'images', img_name)\n",
        "        # 3. load image and store it in self.images (your may want to use tiny_img_dataset.read_rgb_image)\n",
        "        # store the class index in self.targets\n",
        "        # YOUR CODE\n",
        "        image = tiny_img_dataset.read_rgb_image(img_name)\n",
        "\n",
        "        assert image.shape == (64, 64, 3), image.shape\n",
        "        self.images.append(Image.fromarray(image))\n",
        "        self.targets.append(self.class_to_idx[class_name])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.images[index]\n",
        "    image = self.transform(image)\n",
        "    target = self.targets[index]\n",
        "    return image, target"
      ],
      "metadata": {
        "id": "Bcur4d8IzcGT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = TinyImagenetValDataset('tiny-imagenet-200/val', transform=transforms.ToTensor())\n",
        "\n",
        "assert all(train_dataset.classes[i] == val_dataset.classes[i] for i in range(200)), \\\n",
        "    'class order in train and val datasets should be the same'\n",
        "assert all(train_dataset.class_to_idx[elem] == val_dataset.class_to_idx[elem] for elem in train_dataset.classes), \\\n",
        "    'class indices should be the same'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfbydDDd0CS3",
        "outputId": "98f28bcf-63f2-45e6-84b1-7306acc5a7ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tiny-imagenet-200/val: 100%|██████████| 10000/10000 [00:10<00:00, 965.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=2)"
      ],
      "metadata": {
        "id": "T7T_46BS1G72"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_batch_gen = torch.utils.data.DataLoader(val_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=False,\n",
        "                                            num_workers=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBK9v6clDqHJ",
        "outputId": "6fa0de4b-8922-459c-b8fb-3ab5335fe5d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNeXt architecture"
      ],
      "metadata": {
        "id": "Qhe-JVMdDyWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ek4wLSZIDsM2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = train_batch_gen.__iter__().__next__()\n",
        "print(images[0].shape)\n",
        "print(labels[0])\n",
        "plt.imshow(images[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "0m1qATYGD-CA",
        "outputId": "ef72a91c-1966-43fb-86e5-04b6f6cccbe2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 64, 64])\n",
            "tensor(118)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7887b53b21a0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_input_channels = 96\n",
        "n_output_channels = 192\n",
        "layer = nn.Conv2d(n_input_channels, n_output_channels, kernel_size=(7, 7), groups=n_input_channels)\n",
        "\n",
        "parameters_size = sum([elem.size().numel() for elem in layer.parameters()])\n",
        "assert parameters_size == (7*7*192 + 192), parameters_size"
      ],
      "metadata": {
        "id": "1d2Hbv5sHPzm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm2d(nn.Module):\n",
        "  def __init__(self, dim):\n",
        "    super().__init__()\n",
        "    self.ln = nn.LayerNorm(dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    x = self.ln(x)\n",
        "    x = x.permute(0, 3, 1, 2)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ed-E5qBAKx1r"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((2, 5, 4, 3))\n",
        "layer = LayerNorm2d(5)\n",
        "out = layer(x)\n",
        "assert out.size() == x.size()\n",
        "parameters_size = sum([elem.size().numel() for elem in layer.parameters()])\n",
        "assert parameters_size == 10, parameters_size  # 5 for channel weights and 5 for biases"
      ],
      "metadata": {
        "id": "EyJTQNtyNvok"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerScale2d(nn.Module):\n",
        "  def __init__(self, dim, layer_scale_init_value):\n",
        "    super().__init__()\n",
        "    self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim, 1, 1)), requires_grad=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x * self.gamma\n",
        "    return x"
      ],
      "metadata": {
        "id": "iNLVKiQsYBCe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((2, 5, 4, 3))\n",
        "layer_scale_init_value = 1e-5\n",
        "layer = LayerScale2d(5, layer_scale_init_value)\n",
        "out = layer(x)\n",
        "assert out.size() == x.size()\n",
        "assert np.allclose(out.detach().numpy(), x.numpy()*layer_scale_init_value)"
      ],
      "metadata": {
        "id": "fvohaCq1Zd9P"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DropPath(nn.Module):\n",
        "  def __init__(self, drop_prob=None):\n",
        "    super(DropPath, self).__init__()\n",
        "    self.drop_prob = drop_prob\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.drop_prob == 0. or not self.training:\n",
        "      return x\n",
        "    keep_prob = 1 - self.drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
        "    random_tensor = torch.rand(shape, device=x.device)\n",
        "    binary_tensor = (random_tensor < keep_prob).to(x.dtype)\n",
        "    out = x * binary_tensor / keep_prob\n",
        "    return out"
      ],
      "metadata": {
        "id": "oWQKCT30ZfdG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = DropPath(0.5)\n",
        "\n",
        "x = torch.rand((10,5,4,3))\n",
        "\n",
        "layer.eval()\n",
        "out = layer(x)\n",
        "assert out.size() == x.size()\n",
        "assert (out == x).all()\n",
        "\n",
        "layer.train()\n",
        "out = layer(x)\n",
        "assert out.size() == x.size()\n",
        "dropped_samples_mask = torch.isclose(out, torch.zeros([1])).all(dim=(1,2,3))\n",
        "n_dropped_samples = dropped_samples_mask.to(float).sum()\n",
        "assert n_dropped_samples > 2 and n_dropped_samples < 8, n_dropped_samples\n",
        "\n",
        "layer = DropPath(0.1)\n",
        "out = layer(x)\n",
        "dropped_samples_mask = torch.isclose(out, torch.zeros([1])).all(dim=(1,2,3))\n",
        "scaled_samples_mask = torch.isclose(out, x/0.9).all(dim=(1,2,3))\n",
        "assert torch.logical_or(dropped_samples_mask, scaled_samples_mask).all()"
      ],
      "metadata": {
        "id": "Ai9recstbAmP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNextBlock(nn.Module):\n",
        "    def __init__(self, dim, drop_rate=0., layer_scale_init_value=1e-6, use_bn=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # YOUR CODE: define self.depthwise_conv  self.pointwise_conv1 self.pointwise_conv2\n",
        "        self.depthwise_conv = nn.Conv2d(\n",
        "            in_channels=dim,\n",
        "            out_channels=dim,\n",
        "            kernel_size=(5, 5),\n",
        "            padding=2,\n",
        "            groups=dim\n",
        "        )  # depthwise conv 5x5, padding 2, dim->dim\n",
        "\n",
        "        self.norm = LayerNorm2d(dim) if not use_bn else nn.BatchNorm2d(dim)\n",
        "\n",
        "        self.pointwise_conv1 = nn.Conv2d(\n",
        "            in_channels=dim,\n",
        "            out_channels=dim * 4,\n",
        "            kernel_size=(1, 1)\n",
        "        )  # 1x1 conv, dim -> dim*4  YOUR CODE\n",
        "\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "        self.pointwise_conv2 = nn.Conv2d(\n",
        "            in_channels=dim * 4,\n",
        "            out_channels=dim,\n",
        "            kernel_size=(1, 1)\n",
        "        )  # 1x1 conv, 4*dim -> dim YOUR CODE\n",
        "\n",
        "        self.layer_scale = LayerScale2d(dim, layer_scale_init_value) if layer_scale_init_value > 0 else nn.Identity()\n",
        "        self.drop_path = DropPath(drop_rate) if drop_rate is not None and drop_rate > 0. else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = x\n",
        "        # YOUR CODE: sequentially apply to x: depthwise_conv + norm + pointwise_conv1 + activation + pointwise_conv2 + layer_scale\n",
        "        x = self.depthwise_conv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.pointwise_conv1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pointwise_conv2(x)\n",
        "        x = self.layer_scale(x)\n",
        "\n",
        "        x = input + self.drop_path(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kvGeAIpxb2y1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_w_ln = ConvNextBlock(7, 0.1, 1e-6, use_bn=False)\n",
        "\n",
        "x = torch.rand([2,7,4,3])\n",
        "out = block_w_ln(x)\n",
        "\n",
        "assert out.size() == x.size()\n",
        "n_dwconv_parameters = sum([elem.size().numel() for elem in block_w_ln.depthwise_conv.parameters()])\n",
        "assert n_dwconv_parameters == 5*5*7 + 7\n",
        "n_pwconv1_parameters = sum([elem.size().numel() for elem in block_w_ln.pointwise_conv1.parameters()])\n",
        "assert n_pwconv1_parameters == 7*7*4 + 7*4\n",
        "n_pwconv2_parameters = sum([elem.size().numel() for elem in block_w_ln.pointwise_conv2.parameters()])\n",
        "assert n_pwconv2_parameters == 7*7*4 + 7"
      ],
      "metadata": {
        "id": "sKsVC4lHcW0O"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_w_bn = ConvNextBlock(7, 0.1, 1e-6, use_bn=True)\n",
        "\n",
        "x = torch.rand([2,7,4,3])\n",
        "out = block_w_bn(x)\n",
        "assert out.size() == x.size()\n",
        "\n",
        "n_block1_parameters = sum([elem.size().numel() for elem in block_w_ln.parameters()])\n",
        "n_block2_parameters = sum([elem.size().numel() for elem in block_w_bn.parameters()])\n",
        "assert n_block1_parameters == n_block2_parameters"
      ],
      "metadata": {
        "id": "I6eZzvtdcgZx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "class GlobalAveragePool(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.mean(x, dim=self.dim)"
      ],
      "metadata": {
        "id": "W_Cula852hZz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_stem(out_channels, use_bn):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=out_channels, kernel_size=(2, 2), stride=2, padding=0), # YOUR CODE; conv 2x2, stride 2, padding 0\n",
        "        nn.BatchNorm2d(out_channels) if use_bn else LayerNorm2d(out_channels)\n",
        "    )\n",
        "\n",
        "def create_downscale_block(in_channels, out_channels, use_bn):\n",
        "    return nn.Sequential(\n",
        "        nn.BatchNorm2d(in_channels) if use_bn else LayerNorm2d(in_channels),\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=(2, 2), stride=2)  # YOUR CODE: conv 2x2, stride 2, padding 0\n",
        "    )"
      ],
      "metadata": {
        "id": "ngXgK7H03DHy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_convnext_like_network(config=None, use_bn=False, drop_rate=None):\n",
        "    \"\"\"\n",
        "    Creates ConvNeXt like network according to config\n",
        "    \"\"\"\n",
        "    model = nn.Sequential()\n",
        "\n",
        "    default_config = [[32, 32], [64, 64], [128, 128]]\n",
        "    config = config or default_config\n",
        "\n",
        "    stem_out_channels = config[0][0]\n",
        "    # YOUR CODE: create stem\n",
        "    model.add_module('stem', create_stem(stem_out_channels, use_bn))\n",
        "\n",
        "    # progressivily increase drop rate from 0 to 'drop_rate'\n",
        "    drop_rates = np.linspace(0, drop_rate, sum([len(e) for e in config])) if drop_rate is not None else None\n",
        "\n",
        "    layer_index = 0\n",
        "    for block_index in range(len(config)):\n",
        "        for layer_index_in_block in range(len(config[block_index])):\n",
        "            out_channels = config[block_index][layer_index_in_block]\n",
        "            layer_drop_rate = drop_rates[layer_index] if drop_rates is not None else None\n",
        "\n",
        "            # YOUR CODE: add ConvNextBlock\n",
        "            model.add_module(f\"{block_index}_{layer_index_in_block}\", ConvNextBlock(out_channels, layer_drop_rate, ))\n",
        "            layer_index += 1\n",
        "\n",
        "        if block_index != len(config) - 1:\n",
        "            downscale_in_channels = out_channels\n",
        "            downscale_out_channels = config[block_index+1][0]\n",
        "            # YOUR CODE: add downscale block\n",
        "            model.add_module(f'downscale_{block_index}', create_downscale_block(downscale_in_channels, downscale_out_channels, use_bn))\n",
        "\n",
        "    model.add_module('pool', GlobalAveragePool(dim=(2,3)))\n",
        "    model.add_module('norm_final', nn.BatchNorm1d(out_channels) if use_bn else nn.LayerNorm(out_channels))\n",
        "    model.add_module('logits', nn.Linear(out_channels, 200))\n",
        "    return model"
      ],
      "metadata": {
        "id": "cpc5zwKq6ITC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training technics"
      ],
      "metadata": {
        "id": "JpjkBAuu-bHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(predictions, gt, label_smoothing=0.0):\n",
        "    return F.cross_entropy(predictions, gt, label_smoothing=label_smoothing).mean()"
      ],
      "metadata": {
        "id": "fF1kePpw-VpM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_averaged_model(model, decay=0.999):\n",
        "    # YOUR CODE: create AveragedModel instance with ema multi_avg_fn (dont forget to use 'decay' parameter)\n",
        "    averaged_model = torch.optim.swa_utils.AveragedModel(model, multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(decay))\n",
        "\n",
        "    return averaged_model"
      ],
      "metadata": {
        "id": "RiiPtO36_-dO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def eval_model(model, data_generator):\n",
        "    accuracy = []\n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_generator:\n",
        "            X_batch = X_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            y_pred = logits.max(1)[1].data\n",
        "            accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n",
        "    return np.mean(accuracy)\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, train_data_generator, ema_model=None, label_smoothing=0.0):\n",
        "    train_loss = []\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in tqdm.tqdm(train_data_generator):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # YOUR CODE: move X_batch, y_batch to 'device', compute model outputs on X_batch,\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        predictions = model(X_batch)\n",
        "\n",
        "        loss = compute_loss(predictions, y_batch, label_smoothing)\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ema_model is not None:\n",
        "            # YOUR CODE: update parameters of ema model here (see pytorch doc on AveragedModel)\n",
        "            ema_model.update_parameters(model)\n",
        "\n",
        "        # metrics\n",
        "        train_loss.append(loss.cpu().data.numpy())\n",
        "    return np.mean(train_loss)\n",
        "\n",
        "\n",
        "def get_input_for_bn_recompute(data_generator):\n",
        "    for i, (x, y) in enumerate(data_generator):\n",
        "        x = x.to(device)\n",
        "        yield x\n",
        "        if i == 100:\n",
        "            break\n",
        "\n",
        "\n",
        "def train_loop(model, optimizer, train_data_generator, val_data_generator, num_epochs, ema_model=None, label_smoothing=0.0):\n",
        "    \"\"\"\n",
        "    num_epochs - total amount of full passes over training data\n",
        "    \"\"\"\n",
        "    train_metrics = defaultdict(list)\n",
        "    val_metrics = defaultdict(list)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_model(model, optimizer, train_data_generator, ema_model, label_smoothing)\n",
        "\n",
        "        if ema_model is not None:\n",
        "            # YOUR CODE: update batchnorm statistics for ema_model (see pytorch doc on AveragedModel)\n",
        "            torch.optim.swa_utils.update_bn(get_input_for_bn_recompute(train_data_generator), ema_model) # you may need get_input_for_bn_recompute() function here\n",
        "\n",
        "        val_accuracy = eval_model(model, val_data_generator)\n",
        "\n",
        "        # Then we print the results for this epoch:\n",
        "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
        "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n",
        "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_accuracy * 100))\n",
        "        train_metrics['loss'].append(train_loss)\n",
        "        val_metrics['accuracy'].append(val_accuracy)\n",
        "\n",
        "        if ema_model:\n",
        "            val_accuracy_ema_model = eval_model(ema_model, val_data_generator)\n",
        "            print(\"  validation accuracy(ema): \\t\\t\\t{:.2f} %\".format(val_accuracy_ema_model * 100))\n",
        "            val_metrics['ema_model_accuracy'].append(val_accuracy_ema_model)\n",
        "\n",
        "    print('Best model accuracy: ', max(val_metrics['accuracy']))\n",
        "    if ema_model:\n",
        "        print('Best ema model accuracy: ', max(val_metrics['ema_model_accuracy']))\n",
        "\n",
        "    plt.plot(val_metrics['accuracy'], label='model')\n",
        "    if ema_model:\n",
        "        plt.plot(val_metrics['ema_model_accuracy'], label='ema_model')\n",
        "    plt.grid()\n",
        "    plt.legend(loc='best')\n",
        "    return train_metrics, val_metrics"
      ],
      "metadata": {
        "id": "2NTWB4bRBuJ1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_convnext_like_network(use_bn=True)\n",
        "model = model.to(device)\n",
        "ema_model = create_averaged_model(model)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_metrics_ema_bn, val_metrics_ema_bn = train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30, ema_model=ema_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "V44CDs4zEBoc",
        "outputId": "6aad255d-fb41-4ca6-ad07-1f92956747b7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [04:12<00:00,  6.20it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 of 30 took 270.160s\n",
            "  training loss (in-iteration): \t4.953119\n",
            "  validation accuracy: \t\t\t7.95 %\n",
            "  validation accuracy(ema): \t\t\t4.68 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 58/1563 [00:08<03:41,  6.78it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-dcabb5e1af5d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_metrics_ema_bn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics_ema_bn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mema_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mema_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-7e7bcbceed4d>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, train_data_generator, val_data_generator, num_epochs, ema_model, label_smoothing)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mema_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mema_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-7e7bcbceed4d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_data_generator, ema_model, label_smoothing)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# enable dropout / batch_norm training behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_convnext_like_network(use_bn=True, drop_rate=0.1)\n",
        "model = model.to(device)\n",
        "ema_model = create_averaged_model(model)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "train_metrics_droppath, val_metrics_droppath = train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30, ema_model=ema_model)"
      ],
      "metadata": {
        "id": "WrP5uQOVFe6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_convnext_like_network(use_bn=True, drop_rate=0.1)\n",
        "model = model.to(device)\n",
        "ema_model = create_averaged_model(model)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "train_metrics_ls, val_metrics_ls = train_loop(\n",
        "    model, opt, train_batch_gen, val_batch_gen, num_epochs=30, ema_model=ema_model, label_smoothing=0.1)"
      ],
      "metadata": {
        "id": "h49Qfv_bLyUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(val_metrics_ema_bn['accuracy'], label='baseline')\n",
        "plt.plot(val_metrics_ema_bn['ema_model_accuracy'], label='ema_baseline')\n",
        "plt.plot(val_metrics_droppath['accuracy'], label='droppath')\n",
        "plt.plot(val_metrics_droppath['ema_model_accuracy'], label='ema_droppath')\n",
        "plt.plot(val_metrics_ls['accuracy'], label='label smoothing')\n",
        "plt.plot(val_metrics_ls['ema_model_accuracy'], label='ema label smoothing')\n",
        "plt.grid()\n",
        "plt.legend(loc='best')\n",
        "plt.ylim([0.35, 0.55])"
      ],
      "metadata": {
        "id": "WRvmhWrjLyJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_convnext_like_network(use_bn=False, drop_rate=0.1)\n",
        "model = model.to(device)\n",
        "ema_model = create_averaged_model(model)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "train_metrics_ln, val_metrics_ln = train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30, ema_model=ema_model)"
      ],
      "metadata": {
        "id": "s9iGQ-rzL2IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(val_metrics_ema_bn['accuracy'], label='baseline')\n",
        "plt.plot(val_metrics_ema_bn['ema_model_accuracy'], label='ema_baseline')\n",
        "plt.plot(val_metrics_droppath['accuracy'], label='droppath')\n",
        "plt.plot(val_metrics_droppath['ema_model_accuracy'], label='ema_droppath')\n",
        "plt.plot(val_metrics_ls['accuracy'], label='label smoothing')\n",
        "plt.plot(val_metrics_ls['ema_model_accuracy'], label='ema label smoothing')\n",
        "plt.plot(val_metrics_ln['accuracy'], label='layer norm')\n",
        "plt.plot(val_metrics_ln['ema_model_accuracy'], label='ema layer norm')\n",
        "plt.grid()\n",
        "plt.legend(loc='best')\n",
        "plt.ylim([0.35, 0.55])"
      ],
      "metadata": {
        "id": "yFzABkq1L5Qj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}