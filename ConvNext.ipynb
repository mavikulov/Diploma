{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0l9Vl8vbhLSNT1zX1fwEK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavikulov/Diploma/blob/main/ConvNext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lmHRF-MwISa",
        "outputId": "7bb23871-1d0c-4680-870b-6fd6588957ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-14 07:39:35--  https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 813 [text/plain]\n",
            "Saving to: ‘tiny_img.py’\n",
            "\n",
            "\rtiny_img.py           0%[                    ]       0  --.-KB/s               \rtiny_img.py         100%[===================>]     813  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-14 07:39:35 (28.1 MB/s) - ‘tiny_img.py’ saved [813/813]\n",
            "\n",
            "--2025-01-14 07:39:35--  https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img_dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1555 (1.5K) [text/plain]\n",
            "Saving to: ‘tiny_img_dataset.py’\n",
            "\n",
            "tiny_img_dataset.py 100%[===================>]   1.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-14 07:39:35 (19.0 MB/s) - ‘tiny_img_dataset.py’ saved [1555/1555]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget --no-check-certificate 'https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img.py' -O tiny_img.py\n",
        "! wget --no-check-certificate 'https://raw.githubusercontent.com/yandexdataschool/deep_vision_and_graphics/fall21/homework01/tiny_img_dataset.py' -O tiny_img_dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "PkLeqUZJHE_f"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tiny_img import download_tinyImg200\n",
        "data_path = '.'\n",
        "download_tinyImg200(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F07XIJEDwMqh",
        "outputId": "3eb9b207-cfe9-4cc7-ea4b-b3e8e6e0a241"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset was downloaded to './tiny-imagenet-200.zip'\n",
            "Extract downloaded dataset to '.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import tqdm\n",
        "\n",
        "def get_computing_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device\n",
        "\n",
        "device = get_computing_device()\n",
        "print(f\"Our main computing device is '{device}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFOBcqFdwtJR",
        "outputId": "30f9f040-277d-4ac6-ca37-48d37d418408"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our main computing device is 'cpu'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.RandomRotation(5),\n",
        "     transforms.ColorJitter(brightness=0.9, contrast=0.7, saturation=0.8, hue=0.2)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "qk9VwucFw9rg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiny_img_dataset\n",
        "# you may use torchvision.datasets.ImageFolder() with the same parameters for loading train dataset\n",
        "train_dataset = tiny_img_dataset.TinyImagenetRAM('tiny-imagenet-200/train', transform=train_transforms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVJMtkFM3wkV",
        "outputId": "b104fc85-65a5-44e6-fc92-e8f77054681b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tiny-imagenet-200/train: 100%|██████████| 200/200 [02:58<00:00,  1.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class TinyImagenetValDataset(Dataset):\n",
        "  def __init__(self, root, transform=transforms.ToTensor):\n",
        "      super().__init__()\n",
        "\n",
        "      self.root = root\n",
        "      with open(os.path.join(root, 'val_annotations.txt')) as f:\n",
        "        annotations = []\n",
        "        for line in f:\n",
        "          img_name, class_label = line.split('\\t')[:2]\n",
        "          annotations.append((img_name, class_label))\n",
        "\n",
        "      # 1. define self.classes - list of sorted class labels from annotations\n",
        "      # it should look like self.classes from \"TinyImagenetRAM\"\n",
        "      # YOUR CODE\n",
        "      self.classes = sorted(set(i[1] for i in annotations))\n",
        "\n",
        "      assert len(self.classes) == 200, len(self.classes)\n",
        "      assert all(self.classes[i] < self.classes[i+1] for i in range(len(self.classes)-1)), 'classes should be ordered'\n",
        "      assert all(isinstance(elem, type(annotations[0][1])) for elem in self.classes), 'your just need to reuse class_labels'\n",
        "\n",
        "      # 2. self.class_to_idx - dict from class label to class index\n",
        "      self.class_to_idx = {item: index for index, item in enumerate(self.classes)}\n",
        "\n",
        "      self.transform = transform\n",
        "\n",
        "      self.images, self.targets = [], []\n",
        "      for img_name, class_name in tqdm.tqdm(annotations, desc=root):\n",
        "        img_name = os.path.join(root, 'images', img_name)\n",
        "        # 3. load image and store it in self.images (your may want to use tiny_img_dataset.read_rgb_image)\n",
        "        # store the class index in self.targets\n",
        "        # YOUR CODE\n",
        "        image = tiny_img_dataset.read_rgb_image(img_name)\n",
        "\n",
        "        assert image.shape == (64, 64, 3), image.shape\n",
        "        self.images.append(Image.fromarray(image))\n",
        "        self.targets.append(self.class_to_idx[class_name])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.images[index]\n",
        "    image = self.transform(image)\n",
        "    target = self.targets[index]\n",
        "    return image, target"
      ],
      "metadata": {
        "id": "Bcur4d8IzcGT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = TinyImagenetValDataset('tiny-imagenet-200/val', transform=transforms.ToTensor())\n",
        "\n",
        "assert all(train_dataset.classes[i] == val_dataset.classes[i] for i in range(200)), \\\n",
        "    'class order in train and val datasets should be the same'\n",
        "assert all(train_dataset.class_to_idx[elem] == val_dataset.class_to_idx[elem] for elem in train_dataset.classes), \\\n",
        "    'class indices should be the same'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfbydDDd0CS3",
        "outputId": "dee8dc07-a383-4158-803e-594112d83c61"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tiny-imagenet-200/val: 100%|██████████| 10000/10000 [00:20<00:00, 478.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=2)"
      ],
      "metadata": {
        "id": "T7T_46BS1G72"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_batch_gen = torch.utils.data.DataLoader(val_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=False,\n",
        "                                            num_workers=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBK9v6clDqHJ",
        "outputId": "5647f061-cb4d-4569-fb3e-0e0e2906a67e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNeXt architecture"
      ],
      "metadata": {
        "id": "Qhe-JVMdDyWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ek4wLSZIDsM2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = train_batch_gen.__iter__().__next__()\n",
        "print(images[0].shape)\n",
        "print(labels[0])\n",
        "plt.imshow(images[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "0m1qATYGD-CA",
        "outputId": "96b4c69a-9d20-4e3d-88c5-5ef7f7223e9d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 64, 64])\n",
            "tensor(37)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x781d29af7c10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_input_channels = 96\n",
        "n_output_channels = 192\n",
        "layer = nn.Conv2d(n_input_channels, n_output_channels, kernel_size=(7, 7), groups=n_input_channels)\n",
        "\n",
        "parameters_size = sum([elem.size().numel() for elem in layer.parameters()])\n",
        "assert parameters_size == (7*7*192 + 192), parameters_size"
      ],
      "metadata": {
        "id": "1d2Hbv5sHPzm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm2d(nn.Module):\n",
        "  def __init__(self, dim):\n",
        "    super().__init__()\n",
        "    self.ln = nn.LayerNorm(dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    x = self.ln(x)\n",
        "    x = x.permute(0, 3, 1, 2)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ed-E5qBAKx1r"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((2, 5, 4, 3))\n",
        "layer = LayerNorm2d(5)\n",
        "out = layer(x)\n",
        "assert out.size() == x.size()\n",
        "parameters_size = sum([elem.size().numel() for elem in layer.parameters()])\n",
        "assert parameters_size == 10, parameters_size  # 5 for channel weights and 5 for biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyJTQNtyNvok",
        "outputId": "b317e69c-679f-43ba-d215-b57f58e13146"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerScale2d(nn.Module):\n",
        "  def __init__(self, dim, layer_scale_init_value):\n",
        "    super().__init__()\n",
        "    self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim, 1, 1)), requires_grad=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x * self.gamma\n",
        "    return x"
      ],
      "metadata": {
        "id": "iNLVKiQsYBCe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((2, 5, 4, 3))\n",
        "layer_scale_init_value = 1e-5\n",
        "layer = LayerScale2d(5, layer_scale_init_value)\n",
        "out = layer(x)\n",
        "assert out.size() == x.size()\n",
        "assert np.allclose(out.detach().numpy(), x.numpy()*layer_scale_init_value)"
      ],
      "metadata": {
        "id": "fvohaCq1Zd9P"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DropPath(nn.Module):\n",
        "  def __init__(self, drop_prob=None):\n",
        "    super(DropPath, self).__init__()\n",
        "    self.drop_prob = drop_prob\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.drop_prob == 0. or not self.training:\n",
        "      return x\n",
        "    keep_prob = 1 - self.drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
        "    random_tensor = torch.rand(shape, device=x.device)\n",
        "    binary_tensor = (random_tensor < keep_prob).to(x.dtype)\n",
        "    out = x * binary_tensor / keep_prob\n",
        "    return out"
      ],
      "metadata": {
        "id": "oWQKCT30ZfdG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = DropPath(0.5)\n",
        "\n",
        "x = torch.rand((10,5,4,3))\n",
        "\n",
        "layer.eval()\n",
        "out = layer(x)\n",
        "assert out.size() == x.size()\n",
        "assert (out == x).all()\n",
        "\n",
        "layer.train()\n",
        "out = layer(x)\n",
        "assert out.size() == x.size()\n",
        "dropped_samples_mask = torch.isclose(out, torch.zeros([1])).all(dim=(1,2,3))\n",
        "n_dropped_samples = dropped_samples_mask.to(float).sum()\n",
        "assert n_dropped_samples > 2 and n_dropped_samples < 8, n_dropped_samples\n",
        "\n",
        "layer = DropPath(0.1)\n",
        "out = layer(x)\n",
        "dropped_samples_mask = torch.isclose(out, torch.zeros([1])).all(dim=(1,2,3))\n",
        "scaled_samples_mask = torch.isclose(out, x/0.9).all(dim=(1,2,3))\n",
        "assert torch.logical_or(dropped_samples_mask, scaled_samples_mask).all()"
      ],
      "metadata": {
        "id": "Ai9recstbAmP"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNextBlock(nn.Module):\n",
        "    def __init__(self, dim, drop_rate=0., layer_scale_init_value=1e-6, use_bn=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # YOUR CODE: define self.depthwise_conv  self.pointwise_conv1 self.pointwise_conv2\n",
        "        self.depthwise_conv = nn.Conv2d(\n",
        "            in_channels=dim,\n",
        "            out_channels=dim,\n",
        "            kernel_size=(5, 5),\n",
        "            padding=2,\n",
        "            groups=dim\n",
        "        )  # depthwise conv 5x5, padding 2, dim->dim\n",
        "\n",
        "        self.norm = LayerNorm2d(dim) if not use_bn else nn.BatchNorm2d(dim)\n",
        "\n",
        "        self.pointwise_conv1 = nn.Conv2d(\n",
        "            in_channels=dim,\n",
        "            out_channels=dim * 4,\n",
        "            kernel_size=(1, 1)\n",
        "        )  # 1x1 conv, dim -> dim*4  YOUR CODE\n",
        "\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "        self.pointwise_conv2 = nn.Conv2d(\n",
        "            in_channels=dim * 4,\n",
        "            out_channels=dim,\n",
        "            kernel_size=(1, 1)\n",
        "        )  # 1x1 conv, 4*dim -> dim YOUR CODE\n",
        "\n",
        "        self.layer_scale = LayerScale2d(dim, layer_scale_init_value) if layer_scale_init_value > 0 else nn.Identity()\n",
        "        self.drop_path = DropPath(drop_rate) if drop_rate is not None and drop_rate > 0. else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = x\n",
        "        # YOUR CODE: sequentially apply to x: depthwise_conv + norm + pointwise_conv1 + activation + pointwise_conv2 + layer_scale\n",
        "        x = self.depthwise_conv(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.pointwise_conv1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pointwise_conv2(x)\n",
        "        x = self.layer_scale(x)\n",
        "\n",
        "        x = input + self.drop_path(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kvGeAIpxb2y1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_w_ln = ConvNextBlock(7, 0.1, 1e-6, use_bn=False)\n",
        "\n",
        "x = torch.rand([2,7,4,3])\n",
        "out = block_w_ln(x)\n",
        "\n",
        "assert out.size() == x.size()\n",
        "n_dwconv_parameters = sum([elem.size().numel() for elem in block_w_ln.depthwise_conv.parameters()])\n",
        "assert n_dwconv_parameters == 5*5*7 + 7\n",
        "n_pwconv1_parameters = sum([elem.size().numel() for elem in block_w_ln.pointwise_conv1.parameters()])\n",
        "assert n_pwconv1_parameters == 7*7*4 + 7*4\n",
        "n_pwconv2_parameters = sum([elem.size().numel() for elem in block_w_ln.pointwise_conv2.parameters()])\n",
        "assert n_pwconv2_parameters == 7*7*4 + 7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKsVC4lHcW0O",
        "outputId": "4267d387-7318-4a34-94a3-5874f58d6aee"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 7, 4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_w_bn = ConvNextBlock(7, 0.1, 1e-6, use_bn=True)\n",
        "\n",
        "x = torch.rand([2,7,4,3])\n",
        "out = block_w_bn(x)\n",
        "assert out.size() == x.size()\n",
        "\n",
        "n_block1_parameters = sum([elem.size().numel() for elem in block_w_ln.parameters()])\n",
        "n_block2_parameters = sum([elem.size().numel() for elem in block_w_bn.parameters()])\n",
        "assert n_block1_parameters == n_block2_parameters"
      ],
      "metadata": {
        "id": "I6eZzvtdcgZx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!L\n",
        "class GlobalAveragePool(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.mean(x, dim=self.dim)"
      ],
      "metadata": {
        "id": "W_Cula852hZz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_stem(out_channels, use_bn):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=out_channels, kernel_size=(2, 2), stride=2, padding=0), # YOUR CODE; conv 2x2, stride 2, padding 0\n",
        "        nn.BatchNorm2d(out_channels) if use_bn else LayerNorm2d(out_channels)\n",
        "    )\n",
        "\n",
        "def create_downscale_block(in_channels, out_channels, use_bn):\n",
        "    return nn.Sequential(\n",
        "        nn.BatchNorm2d(in_channels) if use_bn else LayerNorm2d(in_channels),\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=(2, 2), stride=2)  # YOUR CODE: conv 2x2, stride 2, padding 0\n",
        "    )"
      ],
      "metadata": {
        "id": "ngXgK7H03DHy"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_convnext_like_network(config=None, use_bn=False, drop_rate=None):\n",
        "    \"\"\"\n",
        "    Creates ConvNeXt like network according to config\n",
        "    \"\"\"\n",
        "    model = nn.Sequential()\n",
        "\n",
        "    default_config = [[32, 32], [64, 64], [128, 128]]\n",
        "    config = config or default_config\n",
        "\n",
        "    stem_out_channels = config[0][0]\n",
        "    # YOUR CODE: create stem\n",
        "    model.add_module('stem', create_stem(stem_out_channels, use_bn))\n",
        "\n",
        "    # progressivily increase drop rate from 0 to 'drop_rate'\n",
        "    drop_rates = np.linspace(0, drop_rate, sum([len(e) for e in config])) if drop_rate is not None else None\n",
        "\n",
        "    layer_index = 0\n",
        "    for block_index in range(len(config)):\n",
        "        for layer_index_in_block in range(len(config[block_index])):\n",
        "            out_channels = config[block_index][layer_index_in_block]\n",
        "            layer_drop_rate = drop_rates[layer_index] if drop_rates is not None else None\n",
        "\n",
        "            # YOUR CODE: add ConvNextBlock\n",
        "            model.add_module(f\"{block_index}_{layer_index_in_block}\", ConvNextBlock(out_channels, layer_drop_rate, ))\n",
        "            layer_index += 1\n",
        "\n",
        "        if block_index != len(config) - 1:\n",
        "            downscale_in_channels = out_channels\n",
        "            downscale_out_channels = config[block_index+1][0]\n",
        "            # YOUR CODE: add downscale block\n",
        "            model.add_module(f'downscale_{block_index}', create_downscale_block(downscale_in_channels, downscale_out_channels, use_bn))\n",
        "\n",
        "    model.add_module('pool', GlobalAveragePool(dim=(2,3)))\n",
        "    model.add_module('norm_final', nn.BatchNorm1d(out_channels) if use_bn else nn.LayerNorm(out_channels))\n",
        "    model.add_module('logits', nn.Linear(out_channels, 200))\n",
        "    return model"
      ],
      "metadata": {
        "id": "cpc5zwKq6ITC"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training technics"
      ],
      "metadata": {
        "id": "JpjkBAuu-bHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(predictions, gt, label_smoothing=0.0):\n",
        "    return F.cross_entropy(predictions, gt, label_smoothing=label_smoothing).mean()"
      ],
      "metadata": {
        "id": "fF1kePpw-VpM"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_averaged_model(model, decay=0.999):\n",
        "    # YOUR CODE: create AveragedModel instance with ema multi_avg_fn (dont forget to use 'decay' parameter)\n",
        "    averaged_model = torch.optim.swa_utils.AveragedModel(model, multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(decay))\n",
        "\n",
        "    return averaged_model"
      ],
      "metadata": {
        "id": "RiiPtO36_-dO"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def eval_model(model, data_generator):\n",
        "    accuracy = []\n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_generator:\n",
        "            X_batch = X_batch.to(device)\n",
        "            logits = model(X_batch)\n",
        "            y_pred = logits.max(1)[1].data\n",
        "            accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n",
        "    return np.mean(accuracy)\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, train_data_generator, ema_model=None, label_smoothing=0.0):\n",
        "    train_loss = []\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in tqdm.tqdm(train_data_generator):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # YOUR CODE: move X_batch, y_batch to 'device', compute model outputs on X_batch,\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        predictions = model(X_batch)\n",
        "\n",
        "        loss = compute_loss(predictions, y_batch, label_smoothing)\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if ema_model is not None:\n",
        "            # YOUR CODE: update parameters of ema model here (see pytorch doc on AveragedModel)\n",
        "            ema_model.update_parameters(model)\n",
        "\n",
        "        # metrics\n",
        "        train_loss.append(loss.cpu().data.numpy())\n",
        "    return np.mean(train_loss)\n",
        "\n",
        "\n",
        "def get_input_for_bn_recompute(data_generator):\n",
        "    for i, (x, y) in enumerate(data_generator):\n",
        "        x = x.to(device)\n",
        "        yield x\n",
        "        if i == 100:\n",
        "            break\n",
        "\n",
        "\n",
        "def train_loop(model, optimizer, train_data_generator, val_data_generator, num_epochs, ema_model=None, label_smoothing=0.0):\n",
        "    \"\"\"\n",
        "    num_epochs - total amount of full passes over training data\n",
        "    \"\"\"\n",
        "    train_metrics = defaultdict(list)\n",
        "    val_metrics = defaultdict(list)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_model(model, optimizer, train_data_generator, ema_model, label_smoothing)\n",
        "\n",
        "        if ema_model is not None:\n",
        "            # YOUR CODE: update batchnorm statistics for ema_model (see pytorch doc on AveragedModel)\n",
        "            torch.optim.swa_utils.update_bn(get_input_for_bn_recompute(train_data_generator), ema_model) # you may need get_input_for_bn_recompute() function here\n",
        "\n",
        "        val_accuracy = eval_model(model, val_data_generator)\n",
        "\n",
        "        # Then we print the results for this epoch:\n",
        "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
        "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n",
        "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_accuracy * 100))\n",
        "        train_metrics['loss'].append(train_loss)\n",
        "        val_metrics['accuracy'].append(val_accuracy)\n",
        "\n",
        "        if ema_model:\n",
        "            print(\"  validation accuracy(ema): \\t\\t\\t{:.2f} %\".format(val_accuracy_ema_model * 100))\n",
        "            val_metrics['ema_model_accuracy'].append(val_accuracy_ema_model)\n",
        "\n",
        "    print('Best model accuracy: ', max(val_metrics['accuracy']))\n",
        "    if ema_model:\n",
        "        print('Best ema model accuracy: ', max(val_metrics['ema_model_accuracy']))\n",
        "\n",
        "    plt.plot(val_metrics['accuracy'], label='model')\n",
        "    if ema_model:\n",
        "        plt.plot(val_metrics['ema_model_accuracy'], label='ema_model')\n",
        "    plt.grid()\n",
        "    plt.legend(loc='best')\n",
        "    return train_metrics, val_metrics"
      ],
      "metadata": {
        "id": "2NTWB4bRBuJ1"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V44CDs4zEBoc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}